{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_model4_testdata.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaGona/MachineLearning-Assignments/blob/master/hw2_model4_testdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fV7V8GJUbPYT",
        "colab_type": "code",
        "outputId": "e507fb2b-fbbd-4a55-ef05-2b1ac720fa46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5J1gtNDAbvFG",
        "colab_type": "code",
        "outputId": "dcc7dddf-e233-43e9-f2f3-37ed9884dc32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# Required variables are declared\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "\n",
        "#Loading and shuffling Cifar10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
        "\n",
        "\n",
        "split_index = int(0.8 * x_train.shape[0])\n",
        "\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Dividing data into training and validation sets\n",
        "train_x = x_train[:split_index]\n",
        "train_y = y_train[:split_index]\n",
        "\n",
        "validate_x = x_train[split_index:]\n",
        "validate_y = y_train[split_index:]\n",
        "\n",
        "print(\"\\nnumber of samples in training set: \",len(train_x))\n",
        "print(\"number of samples in validation set: \",len(validate_x))\n",
        "\n",
        "input_shape = train_x.shape[1:]\n",
        "print(\"Shape of images: \",input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 25s 0us/step\n",
            "\n",
            "number of samples in training set:  40000\n",
            "number of samples in validation set:  10000\n",
            "Shape of images:  (32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vS-jRNCbv_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining the model with more layers.\n",
        "def getModel(input_shape):\n",
        "\tmodel = Sequential()\n",
        "\n",
        "\tmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=train_x.shape[1:]))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(Conv2D(32, (3, 3)))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(64, (3, 3), padding='same'))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(Conv2D(64, (3, 3)))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Conv2D(128, (2, 2), padding='same'))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(Conv2D(128, (2, 2)))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\n",
        "\tmodel.add(Dense(1024))\n",
        "\tmodel.add(Activation('relu'))\n",
        "\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\tmodel.add(Dense(num_classes))\n",
        "\tmodel.add(Activation('softmax'))\n",
        "\t   \n",
        "\t \n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\t\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3eQi42ObcCfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model is trained\n",
        "def train_model(model):\n",
        "  # Data Augmentation\n",
        "\tdatagen = ImageDataGenerator(rotation_range=0, width_shift_range=0.1,height_shift_range=0.1,fill_mode='nearest', horizontal_flip=True, vertical_flip=False, rescale=None)\n",
        "\n",
        "\tdatagen.fit(train_x)\n",
        "\n",
        "\tfor e in range(10):\n",
        "\t\tbatches = 0\n",
        "\t\tfor x_batch, y_batch in datagen.flow(train_x, train_y, batch_size=40000):\n",
        "\t\t\tmodel.fit(x_batch, y_batch)\n",
        "\t\t\tbatches += 1\n",
        "\t\t\tif batches >= 1:\n",
        "\t\t\t\t# we need to break the loop by hand because\n",
        "\t\t\t\t# the generator loops indefinitely\n",
        "\t\t\t\tbreak\n",
        "\t\t\t\t\n",
        "\t\t\t\t\n",
        "\treturn model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(validate_x, validate_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35Ikkw10cK8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model is tested  on the validation data\n",
        "def test_model(validate_x, validate_y):\n",
        "\t\n",
        "  score = model.evaluate(validate_x, validate_y, verbose=0)\n",
        "\t\n",
        "  print('Validation loss:', score[0])\n",
        "  print('Validation accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-WoQkmjwcSVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plotted the Validation accuracy against number of epochs\n",
        "def plot_training_graph(training_history):\n",
        "\t\n",
        "\tplotaccuracy = plt.plot(range(1,epochs+1), training_history.history['acc'],range(1,epochs+1), training_history.history['val_acc'])\n",
        "\n",
        "\tplt.xlabel('Number of epochs')\n",
        "\tplt.ylabel('Accuracy')\n",
        "\n",
        "\tplt.legend(('Train Accuracy','Test Accuracy'))\n",
        "\n",
        "\tplt.show(plotaccuracy)\n",
        "\n",
        "\tprint('\\n\\nvalidation loss:', training_history.history['val_loss'][-1])\n",
        "\tprint('validation accuracy:', training_history.history['val_acc'][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7yTfu5CsccJO",
        "colab_type": "code",
        "outputId": "60533c9a-157d-44df-aff7-d68a71d2efed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4373
        }
      },
      "cell_type": "code",
      "source": [
        "# calling all the methods\n",
        "model = getModel(input_shape)\n",
        "History = train_model(model)\n",
        "test_model(validate_x, validate_y)\n",
        "plot_training_graph(History)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 22s 541us/step - loss: 1.9628 - acc: 0.2563\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 427us/step - loss: 1.6703 - acc: 0.3751\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 18s 454us/step - loss: 1.5523 - acc: 0.4269\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 1.4694 - acc: 0.4619\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 1.4030 - acc: 0.4906\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 425us/step - loss: 1.3404 - acc: 0.5131\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 1.2971 - acc: 0.5305\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 422us/step - loss: 1.2597 - acc: 0.5494\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 421us/step - loss: 1.2245 - acc: 0.5599\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 423us/step - loss: 1.1823 - acc: 0.5753\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 18s 451us/step - loss: 1.0751 - acc: 0.6181 - val_loss: 0.9915 - val_acc: 0.6482\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 18s 454us/step - loss: 1.0450 - acc: 0.6286 - val_loss: 0.9633 - val_acc: 0.6606\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 18s 460us/step - loss: 1.0136 - acc: 0.6389 - val_loss: 0.9290 - val_acc: 0.6709\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.9902 - acc: 0.6475 - val_loss: 0.9344 - val_acc: 0.6656\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.9637 - acc: 0.6575 - val_loss: 0.9021 - val_acc: 0.6769\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.9422 - acc: 0.6655 - val_loss: 0.8698 - val_acc: 0.6886\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.9179 - acc: 0.6731 - val_loss: 0.8760 - val_acc: 0.6947\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.8985 - acc: 0.6828 - val_loss: 0.8790 - val_acc: 0.6865\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 19s 479us/step - loss: 0.8784 - acc: 0.6883 - val_loss: 0.8337 - val_acc: 0.7011\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.8615 - acc: 0.6955 - val_loss: 0.8181 - val_acc: 0.7063\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.8442 - acc: 0.7014 - val_loss: 0.7939 - val_acc: 0.7189\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.8276 - acc: 0.7077 - val_loss: 0.7842 - val_acc: 0.7240\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.8086 - acc: 0.7141 - val_loss: 0.7901 - val_acc: 0.7150\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.7957 - acc: 0.7174 - val_loss: 0.7592 - val_acc: 0.7342\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.7811 - acc: 0.7243 - val_loss: 0.7514 - val_acc: 0.7320\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 19s 481us/step - loss: 0.7658 - acc: 0.7281 - val_loss: 0.7279 - val_acc: 0.7436\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.7508 - acc: 0.7359 - val_loss: 0.7215 - val_acc: 0.7462\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.7400 - acc: 0.7389 - val_loss: 0.7269 - val_acc: 0.7402\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.7249 - acc: 0.7432 - val_loss: 0.7008 - val_acc: 0.7496\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.7126 - acc: 0.7468 - val_loss: 0.7221 - val_acc: 0.7412\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.6984 - acc: 0.7525 - val_loss: 0.6834 - val_acc: 0.7573\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6870 - acc: 0.7591 - val_loss: 0.6749 - val_acc: 0.7610\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6787 - acc: 0.7596 - val_loss: 0.6666 - val_acc: 0.7633\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6676 - acc: 0.7645 - val_loss: 0.6617 - val_acc: 0.7636\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6564 - acc: 0.7669 - val_loss: 0.6536 - val_acc: 0.7690\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6502 - acc: 0.7722 - val_loss: 0.6792 - val_acc: 0.7578\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.6354 - acc: 0.7763 - val_loss: 0.6629 - val_acc: 0.7683\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6280 - acc: 0.7780 - val_loss: 0.6395 - val_acc: 0.7781\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.6209 - acc: 0.7815 - val_loss: 0.6508 - val_acc: 0.7708\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.6069 - acc: 0.7859 - val_loss: 0.6285 - val_acc: 0.7771\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.6039 - acc: 0.7866 - val_loss: 0.6311 - val_acc: 0.7787\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5945 - acc: 0.7891 - val_loss: 0.6412 - val_acc: 0.7760\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 19s 475us/step - loss: 0.5827 - acc: 0.7956 - val_loss: 0.6098 - val_acc: 0.7852\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.5776 - acc: 0.7976 - val_loss: 0.6226 - val_acc: 0.7826\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5672 - acc: 0.7979 - val_loss: 0.6166 - val_acc: 0.7832\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 19s 475us/step - loss: 0.5643 - acc: 0.8023 - val_loss: 0.6105 - val_acc: 0.7877\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5550 - acc: 0.8048 - val_loss: 0.6133 - val_acc: 0.7862\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.5475 - acc: 0.8064 - val_loss: 0.6096 - val_acc: 0.7874\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5423 - acc: 0.8075 - val_loss: 0.6152 - val_acc: 0.7875\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5325 - acc: 0.8113 - val_loss: 0.6062 - val_acc: 0.7905\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 19s 479us/step - loss: 0.5257 - acc: 0.8138 - val_loss: 0.5878 - val_acc: 0.7972\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5235 - acc: 0.8141 - val_loss: 0.5825 - val_acc: 0.7978\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.5166 - acc: 0.8183 - val_loss: 0.5768 - val_acc: 0.8007\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.5074 - acc: 0.8194 - val_loss: 0.5816 - val_acc: 0.7977\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.5011 - acc: 0.8221 - val_loss: 0.5807 - val_acc: 0.7996\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.4990 - acc: 0.8226 - val_loss: 0.5982 - val_acc: 0.7908\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4926 - acc: 0.8250 - val_loss: 0.5708 - val_acc: 0.8022\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 19s 479us/step - loss: 0.4921 - acc: 0.8267 - val_loss: 0.5701 - val_acc: 0.8046\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4849 - acc: 0.8276 - val_loss: 0.5607 - val_acc: 0.8079\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.4771 - acc: 0.8318 - val_loss: 0.5643 - val_acc: 0.8104\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4696 - acc: 0.8331 - val_loss: 0.5690 - val_acc: 0.8029\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.4700 - acc: 0.8322 - val_loss: 0.5663 - val_acc: 0.8026\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.4655 - acc: 0.8346 - val_loss: 0.5692 - val_acc: 0.8030\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.4572 - acc: 0.8375 - val_loss: 0.5649 - val_acc: 0.8058\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.4493 - acc: 0.8401 - val_loss: 0.5472 - val_acc: 0.8102\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.4461 - acc: 0.8405 - val_loss: 0.5554 - val_acc: 0.8098\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.4414 - acc: 0.8428 - val_loss: 0.5642 - val_acc: 0.8060\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.4388 - acc: 0.8448 - val_loss: 0.5567 - val_acc: 0.8090\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4356 - acc: 0.8446 - val_loss: 0.5435 - val_acc: 0.8128\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4297 - acc: 0.8473 - val_loss: 0.5448 - val_acc: 0.8121\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4282 - acc: 0.8467 - val_loss: 0.5491 - val_acc: 0.8112\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.4212 - acc: 0.8482 - val_loss: 0.5362 - val_acc: 0.8170\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4183 - acc: 0.8506 - val_loss: 0.5465 - val_acc: 0.8119\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 19s 481us/step - loss: 0.4106 - acc: 0.8523 - val_loss: 0.5491 - val_acc: 0.8135\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.4137 - acc: 0.8556 - val_loss: 0.5601 - val_acc: 0.8112\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.3993 - acc: 0.8576 - val_loss: 0.5461 - val_acc: 0.8159\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 19s 475us/step - loss: 0.4064 - acc: 0.8535 - val_loss: 0.5598 - val_acc: 0.8094\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3963 - acc: 0.8593 - val_loss: 0.5548 - val_acc: 0.8145\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3944 - acc: 0.8582 - val_loss: 0.5518 - val_acc: 0.8132\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3869 - acc: 0.8621 - val_loss: 0.5596 - val_acc: 0.8118\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3849 - acc: 0.8628 - val_loss: 0.5545 - val_acc: 0.8125\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3864 - acc: 0.8615 - val_loss: 0.5392 - val_acc: 0.8234\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 19s 479us/step - loss: 0.3820 - acc: 0.8649 - val_loss: 0.5400 - val_acc: 0.8181\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3727 - acc: 0.8664 - val_loss: 0.5618 - val_acc: 0.8098\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3701 - acc: 0.8680 - val_loss: 0.5539 - val_acc: 0.8184\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3633 - acc: 0.8697 - val_loss: 0.5698 - val_acc: 0.8159\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3648 - acc: 0.8694 - val_loss: 0.5428 - val_acc: 0.8192\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3588 - acc: 0.8691 - val_loss: 0.5496 - val_acc: 0.8178\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3617 - acc: 0.8687 - val_loss: 0.5355 - val_acc: 0.8207\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3532 - acc: 0.8748 - val_loss: 0.5481 - val_acc: 0.8189\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3484 - acc: 0.8733 - val_loss: 0.5461 - val_acc: 0.8195\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3512 - acc: 0.8735 - val_loss: 0.5486 - val_acc: 0.8187\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3472 - acc: 0.8770 - val_loss: 0.5478 - val_acc: 0.8198\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3461 - acc: 0.8757 - val_loss: 0.5503 - val_acc: 0.8172\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3404 - acc: 0.8766 - val_loss: 0.5420 - val_acc: 0.8231\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3349 - acc: 0.8793 - val_loss: 0.5387 - val_acc: 0.8233\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3354 - acc: 0.8800 - val_loss: 0.5414 - val_acc: 0.8180\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.3312 - acc: 0.8824 - val_loss: 0.5405 - val_acc: 0.8258\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3315 - acc: 0.8818 - val_loss: 0.5431 - val_acc: 0.8200\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3240 - acc: 0.8821 - val_loss: 0.5605 - val_acc: 0.8166\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3267 - acc: 0.8830 - val_loss: 0.5397 - val_acc: 0.8212\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3232 - acc: 0.8836 - val_loss: 0.5436 - val_acc: 0.8228\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 19s 478us/step - loss: 0.3221 - acc: 0.8831 - val_loss: 0.5333 - val_acc: 0.8244\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3166 - acc: 0.8858 - val_loss: 0.5494 - val_acc: 0.8230\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.3162 - acc: 0.8860 - val_loss: 0.5414 - val_acc: 0.8261\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 19s 479us/step - loss: 0.3138 - acc: 0.8891 - val_loss: 0.5377 - val_acc: 0.8254\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 19s 477us/step - loss: 0.3080 - acc: 0.8896 - val_loss: 0.5585 - val_acc: 0.8217\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 19s 475us/step - loss: 0.3116 - acc: 0.8863 - val_loss: 0.5315 - val_acc: 0.8250\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.3043 - acc: 0.8912 - val_loss: 0.5362 - val_acc: 0.8245\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 19s 476us/step - loss: 0.2980 - acc: 0.8928 - val_loss: 0.5438 - val_acc: 0.8230\n",
            "Validation loss: 0.5437827802181244\n",
            "Validation accuracy: 0.823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "validation loss: 0.5437827802181244\n",
            "validation accuracy: 0.823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nCgrNPXYREwP",
        "colab_type": "code",
        "outputId": "c0f18da4-20f8-4371-abfc-ce78f25c9c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Model is tested in this method on the test data\n",
        "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
        "print('Test Loss:', scores[0])\n",
        "print('Test Accuracy:', scores[1]* 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 129us/step\n",
            "Test Loss: 0.5523526725053787\n",
            "Test Accuracy: 82.55\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
